# utils/data_processor.py
import pandas as pd
import numpy as np
from typing import Union, Optional
import os
import logging

logger = logging.getLogger(__name__)

class DataProcessor:
    """Classe para processamento de dados de vendas"""
    
    def __init__(self):
        self.supported_formats = ['.csv', '.xlsx', '.xls']
        logger.debug("DataProcessor inicializado")
        
    def load_data(self, filepath: str) -> pd.DataFrame:
        """Carrega dados do arquivo"""
        logger.info(f"üìÇ Carregando arquivo: {filepath}")
        file_ext = os.path.splitext(filepath)[1].lower()
        
        if file_ext not in self.supported_formats:
            logger.error(f"‚ùå Formato n√£o suportado: {file_ext}")
            raise ValueError(f"Formato n√£o suportado: {file_ext}")
        
        try:
            if file_ext == '.csv':
                df = pd.read_csv(filepath)
                logger.info(f"‚úÖ CSV carregado: {df.shape[0]} linhas, {df.shape[1]} colunas")
            else:
                df = pd.read_excel(filepath)
                logger.info(f"‚úÖ Excel carregado: {df.shape[0]} linhas, {df.shape[1]} colunas")
        except Exception as e:
            logger.error(f"‚ùå Erro ao ler arquivo: {e}")
            raise
        
        return self.preprocess_data(df)
    
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Pr√©-processa os dados para an√°lise"""
        logger.info("üîÑ Iniciando pr√©-processamento")
        logger.debug(f"Colunas originais: {list(df.columns)}")
        
        # Verificar colunas obrigat√≥rias
        required_columns = ['sku', 'sales']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logger.warning(f"‚ö†Ô∏è Colunas obrigat√≥rias faltando: {missing_columns}")
            logger.info("üîç Tentando identificar colunas por padr√µes...")
            df = self._identify_columns(df)
            logger.debug(f"Colunas ap√≥s identifica√ß√£o: {list(df.columns)}")
        
        # Converter tipos de dados
        if 'sales' in df.columns:
            before_count = len(df)
            df['sales'] = pd.to_numeric(df['sales'], errors='coerce')
            df = df.dropna(subset=['sales'])
            after_count = len(df)
            if before_count != after_count:
                logger.warning(f"‚ö†Ô∏è {before_count - after_count} linhas removidas (sales inv√°lidas)")
        
        # Adicionar colunas se n√£o existirem
        if 'date' not in df.columns:
            logger.info("üìÖ Criando coluna de datas fict√≠cias")
            df['date'] = pd.date_range(start='2023-01-01', periods=len(df), freq='D')
        else:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
        
        if 'description' not in df.columns:
            df['description'] = df['sku'].astype(str)
        
        if 'category' not in df.columns:
            df['category'] = 'Geral'
        
        logger.info(f"‚úÖ Pr√©-processamento conclu√≠do: {df.shape}")
        return df
    
    def _identify_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """Identifica colunas por padr√µes comuns"""
        column_mapping = {}
        
        for col in df.columns:
            col_lower = str(col).lower()
            logger.debug(f"Analisando coluna: '{col}' (lower: '{col_lower}')")
            
            # Identificar coluna SKU
            if any(term in col_lower for term in ['sku', 'codigo', 'c√≥digo', 'produto', 'item']):
                column_mapping[col] = 'sku'
                logger.info(f"‚úÖ Coluna '{col}' identificada como SKU")
            
            # Identificar coluna de vendas
            elif any(term in col_lower for term in ['venda', 'sales', 'quantidade', 'qty', 'volume']):
                column_mapping[col] = 'sales'
                logger.info(f"‚úÖ Coluna '{col}' identificada como VENDAS")
            
            # Identificar coluna de data
            elif any(term in col_lower for term in ['data', 'date', 'periodo', 'per√≠odo']):
                column_mapping[col] = 'date'
                logger.info(f"‚úÖ Coluna '{col}' identificada como DATA")
            
            # Identificar coluna de descri√ß√£o
            elif any(term in col_lower for term in ['desc', 'nome', 'name']):
                column_mapping[col] = 'description'
                logger.info(f"‚úÖ Coluna '{col}' identificada como DESCRI√á√ÉO")
            
            # Identificar coluna de categoria
            elif any(term in col_lower for term in ['categ', 'grupo', 'group']):
                column_mapping[col] = 'category'
                logger.info(f"‚úÖ Coluna '{col}' identificada como CATEGORIA")
        
        # Renomear colunas
        if column_mapping:
            df = df.rename(columns=column_mapping)
            logger.info(f"üìù {len(column_mapping)} colunas renomeadas")
        
        return df
    
    def validate_data(self, df: pd.DataFrame) -> tuple[bool, list]:
        """Valida os dados"""
        errors = []
        logger.info("üîç Validando dados...")
        
        # Verificar se h√° dados
        if df.empty:
            errors.append("DataFrame est√° vazio")
            logger.error("‚ùå DataFrame vazio")
        
        # Verificar colunas obrigat√≥rias
        required_columns = ['sku', 'sales']
        missing = [col for col in required_columns if col not in df.columns]
        if missing:
            errors.append(f"Colunas obrigat√≥rias faltando: {missing}")
            logger.error(f"‚ùå Colunas faltando: {missing}")
        
        # Verificar valores negativos em vendas
        if 'sales' in df.columns and (df['sales'] < 0).any():
            errors.append("Existem valores negativos em vendas")
            logger.warning("‚ö†Ô∏è Valores negativos detectados em vendas")
        
        is_valid = len(errors) == 0
        if is_valid:
            logger.info("‚úÖ Dados v√°lidos")
        else:
            logger.error(f"‚ùå Dados inv√°lidos: {errors}")
        
        return is_valid, errors
